{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676864cc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a305ec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed\\miniconda3\\envs\\MachineLab10\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split as sklearn_split\n",
    "from surprise import SVD, SVDpp, Dataset, Reader, KNNBasic, CoClustering, NMF, Prediction\n",
    "from surprise.model_selection import GridSearchCV, train_test_split\n",
    "from joblib import dump, load\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import coo_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59a0c1",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70f68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring train_df as None to avoid undefined variable error\n",
    "train_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c8275",
   "metadata": {},
   "source": [
    "## Load MovieLens 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bccc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating\n",
       "0       1     1193       5\n",
       "1       1      661       3\n",
       "2       1      914       3\n",
       "3       1     3408       4\n",
       "4       1     2355       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_1m_df = pd.read_csv(\"../../preprocessing/ratings_1m.csv\")\n",
    "ratings_1m_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b930fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000209 entries, 0 to 1000208\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count    Dtype\n",
      "---  ------   --------------    -----\n",
      " 0   UserID   1000209 non-null  int64\n",
      " 1   MovieID  1000209 non-null  int64\n",
      " 2   Rating   1000209 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 22.9 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_1m_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b03e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000209 entries, 0 to 1000208\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   UserID   1000209 non-null  int32  \n",
      " 1   MovieID  1000209 non-null  int32  \n",
      " 2   Rating   1000209 non-null  float16\n",
      "dtypes: float16(1), int32(2)\n",
      "memory usage: 9.5 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_1m_df['UserID'] = ratings_1m_df['UserID'].astype('int32')\n",
    "ratings_1m_df['MovieID'] = ratings_1m_df['MovieID'].astype('int32')\n",
    "ratings_1m_df['Rating'] = ratings_1m_df['Rating'].astype('float16')\n",
    "\n",
    "ratings_1m_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642bfaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "4.0    348971\n",
       "3.0    261197\n",
       "5.0    226310\n",
       "2.0    107557\n",
       "1.0     56174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_1m_df[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda73168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id  num_ratings\n",
      "0           1           53\n",
      "1           2          129\n",
      "2           3           51\n",
      "3           4           21\n",
      "4           5          198\n",
      "...       ...          ...\n",
      "6035     6036          888\n",
      "6036     6037          202\n",
      "6037     6038           20\n",
      "6038     6039          123\n",
      "6039     6040          341\n",
      "\n",
      "[6040 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings_per_user = ratings_1m_df.groupby('UserID')['Rating'].count().reset_index()\n",
    "ratings_per_user.columns = ['user_id', 'num_ratings']\n",
    "print(ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b1853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6040.000000\n",
      "mean      165.597517\n",
      "std       192.747029\n",
      "min        20.000000\n",
      "10%        27.000000\n",
      "50%        96.000000\n",
      "90%       400.000000\n",
      "max      2314.000000\n",
      "Name: num_ratings, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stats = ratings_per_user['num_ratings'].describe(percentiles=[0.1, 0.5, 0.9])\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd29a411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000209e+06\n",
       "mean     1.865540e+03\n",
       "std      1.096041e+03\n",
       "min      1.000000e+00\n",
       "25%      1.030000e+03\n",
       "50%      1.835000e+03\n",
       "75%      2.770000e+03\n",
       "max      3.952000e+03\n",
       "Name: MovieID, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_1m_df[\"MovieID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b01c6a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000209e+06\n",
       "mean     3.024512e+03\n",
       "std      1.728413e+03\n",
       "min      1.000000e+00\n",
       "25%      1.506000e+03\n",
       "50%      3.070000e+03\n",
       "75%      4.476000e+03\n",
       "max      6.040000e+03\n",
       "Name: UserID, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_1m_df[\"UserID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c2264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(ratings_1m_df['Rating'].min(), ratings_1m_df['Rating'].max()))\n",
    "data = Dataset.load_from_df(ratings_1m_df[['UserID', 'MovieID', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a6d89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e0204",
   "metadata": {},
   "source": [
    "### Load 1M for LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf10756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = sklearn_split(ratings_1m_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a2573",
   "metadata": {},
   "source": [
    "## Load MovieLens 10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59aad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_10m_df = pd.read_csv(\"../../preprocessing/ratings_10m.csv\")\n",
    "ratings_10m_df = ratings_10m_df.drop('Timestamp', axis=1)\n",
    "\n",
    "ratings_10m_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_10m_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10067f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_10m_df['UserID'] = ratings_10m_df['UserID'].astype('int32')\n",
    "ratings_10m_df['MovieID'] = ratings_10m_df['MovieID'].astype('int32')\n",
    "ratings_10m_df['Rating'] = ratings_10m_df['Rating'].astype('float16')\n",
    "\n",
    "ratings_10m_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_10m_df[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user = ratings_10m_df.groupby('UserID')['Rating'].count().reset_index()\n",
    "ratings_per_user.columns = ['user_id', 'num_ratings']\n",
    "print(ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53796c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ratings_per_user['num_ratings'].describe(percentiles=[0.1, 0.5, 0.9])\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cdffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_10m_df[\"MovieID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_10m_df[\"UserID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e336619",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(ratings_10m_df['Rating'].min(), ratings_10m_df['Rating'].max()))\n",
    "data = Dataset.load_from_df(ratings_10m_df[['UserID', 'MovieID', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b8329",
   "metadata": {},
   "source": [
    "### Load 10M for LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = sklearn_split(ratings_10m_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd6d8f8",
   "metadata": {},
   "source": [
    "## Load MovieLens 32M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff115f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_32m_df = pd.read_csv(\"../../preprocessing/ratings_32m.csv\")\n",
    "ratings_32m_df = ratings_32m_df.drop('Timestamp', axis=1)\n",
    "\n",
    "ratings_32m_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_32m_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_32m_df['UserID'] = ratings_32m_df['UserID'].astype('int32')\n",
    "ratings_32m_df['MovieID'] = ratings_32m_df['MovieID'].astype('int32')\n",
    "ratings_32m_df['Rating'] = ratings_32m_df['Rating'].astype('float16')\n",
    "\n",
    "ratings_32m_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ac183",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_32m_df[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user = ratings_32m_df.groupby('UserID')['Rating'].count().reset_index()\n",
    "ratings_per_user.columns = ['user_id', 'num_ratings']\n",
    "print(ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055aee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ratings_per_user['num_ratings'].describe(percentiles=[0.1, 0.5, 0.9])\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672165a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_32m_df[\"MovieID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25897e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_32m_df[\"UserID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ec3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(ratings_32m_df['Rating'].min(), ratings_32m_df['Rating'].max()))\n",
    "data = Dataset.load_from_df(ratings_32m_df[['UserID', 'MovieID', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b365f91",
   "metadata": {},
   "source": [
    "### Load 32M for LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = sklearn_split(ratings_32m_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699c559",
   "metadata": {},
   "source": [
    "# Models List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c1dde45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameter grids\n",
    "models = [\n",
    "    {\n",
    "        'name': 'LightFM-WARP',\n",
    "        'algo': LightFM,\n",
    "        'params': {\n",
    "            'no_components': [20, 50],\n",
    "            'loss': ['warp'],\n",
    "            'learning_rate': [0.005, 0.01],\n",
    "            'item_alpha': [0.02, 0.1, 0.3],\n",
    "            'user_alpha': [0.02, 0.1, 0.3],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'LightFM-BPR',\n",
    "        'algo': LightFM,\n",
    "        'params': {\n",
    "            'no_components': [20, 50],\n",
    "            'loss': ['bpr'],\n",
    "            'learning_rate': [0.005, 0.01],\n",
    "            'item_alpha': [0.02, 0.1, 0.3],\n",
    "            'user_alpha': [0.02, 0.1, 0.3],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'SVD',\n",
    "        'algo': SVD,\n",
    "        'params': {\n",
    "            'n_factors': [50, 100, 150],\n",
    "            'n_epochs': [20, 30],\n",
    "            'lr_all': [0.005, 0.01],\n",
    "            'reg_all': [0.02, 0.1]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'KNNBasic',\n",
    "        'algo': KNNBasic,\n",
    "        'params': {\n",
    "            'k': [20, 40],\n",
    "            'sim_options': {\n",
    "                'name': ['msd', 'pearson'],\n",
    "                'user_based': [False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'NMF',\n",
    "        'algo': NMF,\n",
    "        'params': {\n",
    "            'n_factors': [10, 15],\n",
    "            'n_epochs': [50, 100]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'CoClustering',\n",
    "        'algo': CoClustering,\n",
    "        'params': {\n",
    "            'n_cltr_u': [3, 5],\n",
    "            'n_cltr_i': [3, 5],\n",
    "            'n_epochs': [20, 30]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de227326",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7102d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE and accuracy metrics\n",
    "def compute_metrics(predictions, tolerance=1):\n",
    "    actuals = np.array([pred.r_ui for pred in predictions])\n",
    "    preds = np.array([pred.est for pred in predictions])\n",
    "    rmse_val = np.sqrt(np.mean((preds - actuals) ** 2))\n",
    "    accuracy = np.mean(np.abs(preds - actuals) <= tolerance) * 100\n",
    "    return {'RMSE': rmse_val, f'Acc (±{tolerance})': accuracy}\n",
    "\n",
    "# Compute precision@k for top-N recommendations\n",
    "def compute_precision_at_k(predictions, k=5, threshold=3):\n",
    "    user_est_true = {}\n",
    "    for pred in predictions:\n",
    "        uid, iid, true_r, est, _ = pred\n",
    "        if uid not in user_est_true:\n",
    "            user_est_true[uid] = []\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    for uid, ratings in user_est_true.items():\n",
    "        ratings.sort(key=lambda x: x[0], reverse=True)  # Sort by predicted rating\n",
    "        top_k = [r[1] >= threshold for r in ratings[:k]]  # True ratings >= threshold\n",
    "        if top_k:\n",
    "            precisions.append(sum(top_k) / len(top_k))\n",
    "    \n",
    "    return np.mean(precisions) if precisions else 0\n",
    "\n",
    "# Convert DataFrame to COO matrix for LightFM\n",
    "def df_to_lightfm(train_df):\n",
    "    # Map UserID and MovieID to consecutive indices\n",
    "    user_ids = train_df['UserID'].unique()\n",
    "    item_ids = train_df['MovieID'].unique()\n",
    "    user_map = {uid: idx for idx, uid in enumerate(user_ids)}\n",
    "    item_map = {iid: idx for idx, iid in enumerate(item_ids)}\n",
    "    \n",
    "    # Prepare data for coo_matrix\n",
    "    rows = [user_map[uid] for uid in train_df['UserID']]\n",
    "    cols = [item_map[iid] for iid in train_df['MovieID']]\n",
    "    data = [1] * len(train_df)  # Binary implicit feedback\n",
    "    \n",
    "    # Create sparse matrix\n",
    "    interactions = coo_matrix((data, (rows, cols)), shape=(len(user_ids), len(item_ids)))\n",
    "    return interactions, user_map, item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee4e401",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "train_df is not loaded. Ensure the `Load *M for LightFM` is run correctly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     interactions, user_map, item_map \u001b[38;5;241m=\u001b[39m df_to_lightfm(train_df)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_df is not loaded. Ensure the `Load *M for LightFM` is run correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: train_df is not loaded. Ensure the `Load *M for LightFM` is run correctly."
     ]
    }
   ],
   "source": [
    "# Prepare interactions matrix for LightFM\n",
    "if train_df is not None:\n",
    "    interactions, user_map, item_map = df_to_lightfm(train_df)\n",
    "else:\n",
    "    raise ValueError(\"train_df is not loaded. Ensure the `Load *M for LightFM` is run correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d2c88",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "best_params_dict = {}\n",
    "for model in models:\n",
    "    if model['algo'] == LightFM:\n",
    "        if train_df is not None:\n",
    "            # LightFM handling\n",
    "            best_score = -np.inf\n",
    "            best_params = {}\n",
    "            for params in ParameterGrid(model['params']):\n",
    "                print(f\"Tuning {model['name']} with params: {params}\")\n",
    "                model = LightFM(**params)\n",
    "                model.fit(interactions, epochs=10, verbose=False)\n",
    "                score = precision_at_k(model, interactions, k=5).mean()\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "\n",
    "            print(f\"Best RMSE: {gs.best_score['rmse']:.4f}\")\n",
    "            print(f\"Best params: {best_params}\")\n",
    "            best_params_dict[model['name']] = best_params\n",
    "        else:\n",
    "            print(f\"Skipping {model['name']} tuning due to missing train_df\")\n",
    "    else:\n",
    "        # Original Surprise handling\n",
    "        print(f\"Tuning {model['name']} with params: {model['params']}\")\n",
    "        gs = GridSearchCV(\n",
    "            model['algo'],\n",
    "            model['params'],\n",
    "            measures=['rmse'],\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            pre_dispatch='2*n_jobs',\n",
    "        )\n",
    "        gs.fit(data)\n",
    "        best_params = gs.best_params['rmse']\n",
    "\n",
    "        print(f\"Best RMSE: {gs.best_score['rmse']:.4f}\")\n",
    "        print(f\"Best params: {best_params}\")\n",
    "        best_params_dict[model['name']] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters to disk\n",
    "dump(best_params_dict, '../output_models/best_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa5236",
   "metadata": {},
   "source": [
    "# Load Model Paramters from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07b2a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load desired parameters from disk\n",
    "best_params_dict = load('../output_models/best_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68aac0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVD': {'n_factors': 150, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}, 'KNNBasic': {'k': 40, 'sim_options': {'name': 'msd', 'user_based': False}}, 'NMF': {'n_factors': 10, 'n_epochs': 100}, 'CoClustering': {'n_cltr_u': 5, 'n_cltr_i': 3, 'n_epochs': 30}}\n"
     ]
    }
   ],
   "source": [
    "print(best_params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b45b1",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0db7d024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping LightFM-WARP due to missing parameters\n",
      "Skipping LightFM-BPR due to missing parameters\n",
      "\n",
      "=== Training SVD ===\n",
      "\n",
      "=== Training KNNBasic ===\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "=== Training NMF ===\n",
      "\n",
      "=== Training CoClustering ===\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation\n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    if model['name'] not in best_params_dict:\n",
    "        print(f\"Skipping {model['name']} due to missing parameters\")\n",
    "        continue\n",
    "    else:\n",
    "        if model['algo'] == LightFM:\n",
    "            if train_df is not None:\n",
    "                # LightFM handling\n",
    "                print(f\"\\n=== Training {model['name']} ===\\n\")\n",
    "                model_name = model['name']\n",
    "                results[model_name] = {}\n",
    "                model = model['algo'](**best_params_dict[model_name])\n",
    "                model.fit(interactions, epochs=30)\n",
    "\n",
    "                # Generate valid test indices (positional)\n",
    "                valid_indices = []\n",
    "                test_user_ids = []\n",
    "                test_item_ids = []\n",
    "                for pos_idx, (idx, row) in enumerate(test_df.iterrows()):\n",
    "                    uid, iid, rating = row['UserID'], row['MovieID'], row['Rating']\n",
    "                    if uid in user_map and iid in item_map:  # Ensure user and item were in training\n",
    "                        valid_indices.append(pos_idx)  # Store positional index\n",
    "                        test_user_ids.append(user_map[uid])\n",
    "                        test_item_ids.append(item_map[iid])\n",
    "\n",
    "                # Predict and scale to rating range\n",
    "                preds = model.predict(test_user_ids, test_item_ids)\n",
    "                min_rating, max_rating = 1, 5\n",
    "                min_pred, max_pred = np.min(preds), np.max(preds)\n",
    "                if max_pred != min_pred:  # Avoid division by zero\n",
    "                    scaled_preds = min_rating + (preds - min_pred) * (max_rating - min_rating) / (max_pred - min_pred)\n",
    "                else:\n",
    "                    scaled_preds = np.full_like(preds, min_rating)  # Fallback if all predictions are the same\n",
    "\n",
    "                # Create Prediction objects using positional indices\n",
    "                predictions = [\n",
    "                    Prediction(\n",
    "                        uid=test_df.iloc[pos_idx]['UserID'],\n",
    "                        iid=test_df.iloc[pos_idx]['MovieID'],\n",
    "                        r_ui=test_df.iloc[pos_idx]['Rating'],\n",
    "                        est=float(scaled_preds[j]),\n",
    "                        details=None,\n",
    "                    )\n",
    "                    for j, pos_idx in enumerate(valid_indices)\n",
    "                ]\n",
    "\n",
    "                results[model_name].update({\n",
    "                    'params': best_params_dict[model_name],\n",
    "                    'metrics': compute_metrics(predictions),\n",
    "                    'precision_at_k': compute_precision_at_k(predictions, k=10, threshold=3)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping {model['name']} training due to missing train_df\")\n",
    "\n",
    "        else:\n",
    "            # Original Surprise handling\n",
    "            print(f\"\\n=== Training {model['name']} ===\")\n",
    "            model_name = model['name']\n",
    "            results[model_name] = {}\n",
    "            model = model['algo'](**best_params_dict[model_name])\n",
    "            model.fit(trainset)\n",
    "            \n",
    "            # Generate predictions\n",
    "            predictions = model.test(testset)\n",
    "            \n",
    "            results[model_name].update({\n",
    "                'params': best_params_dict[model_name],\n",
    "                'metrics': compute_metrics(predictions),\n",
    "                'precision_at_k': compute_precision_at_k(predictions, k=10, threshold=3)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb29e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format results for readability\n",
    "formatted_results = []\n",
    "for model_name, data in results.items():\n",
    "    formatted_results.append({\n",
    "        'Model': model_name,\n",
    "        'RMSE': data['metrics']['RMSE'],\n",
    "        'Acc (±1)': data['metrics']['Acc (±1)'],\n",
    "        'Precision@10': data['precision_at_k'],\n",
    "        'Best Params': str(data['params'])  # Convert dict to string for simplicity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf09452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Results ===\n",
      "\n",
      "                  RMSE   Acc (±1)  Precision@10                                                         Best Params\n",
      "Model                                                                                                              \n",
      "SVD           0.872063  75.718099      0.925831  {'n_factors': 150, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n",
      "KNNBasic      0.914429  73.982964      0.923130      {'k': 40, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
      "NMF           0.898074  74.059947      0.919301                                  {'n_factors': 10, 'n_epochs': 100}\n",
      "CoClustering  0.910022  74.452365      0.919234                      {'n_cltr_u': 5, 'n_cltr_i': 3, 'n_epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "training_report = pd.DataFrame(formatted_results)\n",
    "training_report.set_index('Model', inplace=True)\n",
    "print(\"\\n=== Final Results ===\\n\")\n",
    "print(training_report.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19808f",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55f7a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVD saved successfully to ../output_models/svd_model.pkl!\n",
      "Model KNNBasic saved successfully to ../output_models/knnbasic_model.pkl!\n",
      "Model NMF saved successfully to ../output_models/nmf_model.pkl!\n",
      "Model CoClustering saved successfully to ../output_models/coclustering_model.pkl!\n"
     ]
    }
   ],
   "source": [
    "# Save results, models and data mappings\n",
    "current_date = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "training_report.to_csv(f'../training_results/training_report_{current_date}.csv')\n",
    "\n",
    "if train_df is not None:\n",
    "    dump(user_map, '../output_models/user_map.pkl')\n",
    "    dump(item_map, '../output_models/item_map.pkl')\n",
    "\n",
    "for model in models:\n",
    "    if train_df is None and model['algo'] == LightFM:\n",
    "        continue\n",
    "    else:\n",
    "        # Fixed f-string by using different quote types\n",
    "        file_path = f\"../output_models/{model['name'].lower().replace('-', '_')}_model.pkl\"\n",
    "        dump(model, file_path)\n",
    "        print(f\"Model {model['name']} saved successfully to {file_path}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLab10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
