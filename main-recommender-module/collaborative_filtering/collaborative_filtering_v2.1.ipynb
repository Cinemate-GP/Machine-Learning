{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4d7611",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f27a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid, train_test_split as sklearn_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from surprise import SVD, Dataset, Reader, accuracy, KNNBasic, SlopeOne, CoClustering, NMF, Prediction\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder , StandardScaler\n",
    "from surprise.accuracy import rmse\n",
    "from joblib import Memory, parallel_backend, dump\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb6e37",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59eb5982-6332-4159-b1eb-49659cd700b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>[8]</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>James and the Giant Peach</td>\n",
       "      <td>[3, 4, 12]</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>My Fair Lady</td>\n",
       "      <td>[12, 14]</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Erin Brockovich</td>\n",
       "      <td>[8]</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bug's Life, A</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Gender  Age                            Title  \\\n",
       "0       1     1193       5       0    1  One Flew Over the Cuckoo's Nest   \n",
       "1       1      661       3       0    1        James and the Giant Peach   \n",
       "2       1      914       3       0    1                     My Fair Lady   \n",
       "3       1     3408       4       0    1                  Erin Brockovich   \n",
       "4       1     2355       5       0    1                    Bug's Life, A   \n",
       "\n",
       "       Genres  Year  \n",
       "0         [8]  1975  \n",
       "1  [3, 4, 12]  1996  \n",
       "2    [12, 14]  1964  \n",
       "3         [8]  2000  \n",
       "4   [3, 4, 5]  1998  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../preprocessing/merged_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6dc40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000209 entries, 0 to 1000208\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count    Dtype \n",
      "---  ------   --------------    ----- \n",
      " 0   UserID   1000209 non-null  int64 \n",
      " 1   MovieID  1000209 non-null  int64 \n",
      " 2   Rating   1000209 non-null  int64 \n",
      " 3   Gender   1000209 non-null  int64 \n",
      " 4   Age      1000209 non-null  int64 \n",
      " 5   Title    1000209 non-null  object\n",
      " 6   Genres   1000209 non-null  object\n",
      " 7   Year     1000209 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1741c975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating\n",
       "0       1     1193       5\n",
       "1       1      661       3\n",
       "2       1      914       3\n",
       "3       1     3408       4\n",
       "4       1     2355       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df.drop(columns=[\"Gender\",\"Age\",\"Title\",\"Year\", \"Genres\"])\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6277a887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "4    348971\n",
       "3    261197\n",
       "5    226310\n",
       "2    107557\n",
       "1     56174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6503030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id  num_ratings\n",
      "0           1           53\n",
      "1           2          129\n",
      "2           3           51\n",
      "3           4           21\n",
      "4           5          198\n",
      "...       ...          ...\n",
      "6035     6036          888\n",
      "6036     6037          202\n",
      "6037     6038           20\n",
      "6038     6039          123\n",
      "6039     6040          341\n",
      "\n",
      "[6040 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings_per_user = filtered_df.groupby('UserID')['Rating'].count().reset_index()\n",
    "ratings_per_user.columns = ['user_id', 'num_ratings']\n",
    "print(ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eff3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6040.000000\n",
      "mean      165.597517\n",
      "std       192.747029\n",
      "min        20.000000\n",
      "10%        27.000000\n",
      "50%        96.000000\n",
      "90%       400.000000\n",
      "max      2314.000000\n",
      "Name: num_ratings, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stats = ratings_per_user['num_ratings'].describe(percentiles=[0.1, 0.5, 0.9])\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "020d8e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000209e+06\n",
       "mean     1.865540e+03\n",
       "std      1.096041e+03\n",
       "min      1.000000e+00\n",
       "25%      1.030000e+03\n",
       "50%      1.835000e+03\n",
       "75%      2.770000e+03\n",
       "max      3.952000e+03\n",
       "Name: MovieID, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df[\"MovieID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954089a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000209e+06\n",
       "mean     3.024512e+03\n",
       "std      1.728413e+03\n",
       "min      1.000000e+00\n",
       "25%      1.506000e+03\n",
       "50%      3.070000e+03\n",
       "75%      4.476000e+03\n",
       "max      6.040000e+03\n",
       "Name: UserID, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df[\"UserID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe4d29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_df, _ = sklearn_split(filtered_df, test_size=0.5, random_state=42, stratify=filtered_df['UserID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51b60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(filtered_df['Rating'].min(), filtered_df['Rating'].max()))\n",
    "data = Dataset.load_from_df(filtered_df[['UserID', 'MovieID', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d38c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ada37",
   "metadata": {},
   "source": [
    "# Test Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa578eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprise_to_lightfm(trainset):\n",
    "    \"\"\"Convert Surprise Trainset to COO matrix for LightFM\"\"\"\n",
    "    rows, cols, data = [], [], []\n",
    "    for uid in trainset.all_users():\n",
    "        user_ratings = trainset.ur[uid]\n",
    "        for iid, rating in user_ratings:\n",
    "            rows.append(uid)\n",
    "            cols.append(iid)\n",
    "            data.append(1)  # Use 1 for implicit feedback\n",
    "    return coo_matrix((data, (rows, cols))), trainset.n_users, trainset.n_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f9b453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions, _, _ = surprise_to_lightfm(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfb37387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs\n",
    "assert not np.isnan(interactions.data).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "665163d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zero-interaction users/items\n",
    "interactions = interactions.tocsr()\n",
    "interactions = interactions[interactions.getnnz(1) > 0]  # Remove empty rows\n",
    "interactions = interactions[:, interactions.getnnz(0) > 0]  # Remove empty cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15bb7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameter grids\n",
    "models = [\n",
    "    {\n",
    "        'name': 'LightFM-WARP',\n",
    "        'algo': LightFM,\n",
    "        'params': {\n",
    "            'no_components': [20, 50],\n",
    "            'loss': ['warp'],\n",
    "            'learning_rate': [0.005, 0.01],\n",
    "            'item_alpha': [0.02, 0.1, 0.3],\n",
    "            'user_alpha': [0.02, 0.1, 0.3],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'LightFM-BPR',\n",
    "        'algo': LightFM,\n",
    "        'params': {\n",
    "            'no_components': [20, 50],\n",
    "            'loss': ['bpr'],\n",
    "            'learning_rate': [0.005, 0.01],\n",
    "            'item_alpha': [0.02, 0.1, 0.3],\n",
    "            'user_alpha': [0.02, 0.1, 0.3],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74520f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning LightFM-WARP ===\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-WARP with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'warp', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "\n",
      "=== Tuning LightFM-BPR ===\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.02, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.1, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.005, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 20, 'random_state': 42, 'user_alpha': 0.3}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.02}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.1}\n",
      "Training LightFM-BPR with params: {'item_alpha': 0.3, 'learning_rate': 0.01, 'loss': 'bpr', 'no_components': 50, 'random_state': 42, 'user_alpha': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Tuning results storage\n",
    "best_params = {}\n",
    "\n",
    "# Tuning loop\n",
    "for config in models:\n",
    "    print(f\"\\n=== Tuning {config['name']} ===\")\n",
    "    \n",
    "    if config['algo'] == LightFM:\n",
    "        # LightFM tuning\n",
    "        best_score = -np.inf\n",
    "        best_params = {}\n",
    "        for params in ParameterGrid(config['params']):\n",
    "            print(f\"Training {config['name']} with params: {params}\")\n",
    "            model = LightFM(**params)\n",
    "            model.fit(interactions, epochs=10, verbose=False)\n",
    "            score = precision_at_k(model, interactions, k=5).mean()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "                \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd001af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, tolerance=0.5):\n",
    "    actuals = np.array([pred.r_ui for pred in predictions])\n",
    "    preds = np.array([pred.est for pred in predictions])\n",
    "    \n",
    "    return {\n",
    "        'RMSE': np.sqrt(np.mean((preds - actuals) ** 2)),\n",
    "        f'Acc (±{tolerance})': np.mean(np.abs(preds - actuals) <= tolerance) * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78d9f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all item IDs present in training\n",
    "train_iids = set(trainset.all_items())  # Surprise's inner item IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca5945bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unknown item: 3904\n",
      "Skipping unknown item: 791\n",
      "Skipping unknown item: 624\n",
      "Skipping unknown item: 789\n",
      "Skipping unknown item: 1724\n",
      "Skipping unknown item: 2254\n",
      "Skipping unknown item: 3065\n",
      "Skipping unknown item: 1165\n",
      "Skipping unknown item: 3229\n",
      "Skipping unknown item: 701\n",
      "Skipping unknown item: 3323\n",
      "Skipping unknown item: 791\n",
      "Skipping unknown item: 730\n",
      "Skipping unknown item: 557\n",
      "Skipping unknown item: 3647\n",
      "Skipping unknown item: 655\n",
      "Skipping unknown item: 584\n",
      "Skipping unknown item: 557\n",
      "Skipping unknown item: 774\n",
      "Skipping unknown item: 3881\n",
      "Skipping unknown item: 672\n",
      "Skipping unknown item: 712\n",
      "Skipping unknown item: 2909\n",
      "Skipping unknown item: 789\n",
      "Skipping unknown item: 672\n",
      "Skipping unknown item: 1630\n",
      "Skipping unknown item: 139\n",
      "Skipping unknown item: 1832\n",
      "Skipping unknown item: 712\n",
      "Skipping unknown item: 398\n",
      "Skipping unknown item: 3376\n",
      "Skipping unknown item: 396\n",
      "Skipping unknown item: 868\n",
      "Skipping unknown item: 2226\n",
      "Skipping unknown item: 1118\n",
      "Skipping unknown item: 2563\n"
     ]
    }
   ],
   "source": [
    "filtered_testset = []\n",
    "for (uid, iid, rating) in testset:\n",
    "    try:\n",
    "        # Check if item exists in training set\n",
    "        trainset.to_inner_iid(iid)  # Will throw ValueError if not found\n",
    "        filtered_testset.append((uid, iid, rating))\n",
    "    except ValueError:\n",
    "        print(f\"Skipping unknown item: {iid}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebc7c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(**best_params)\n",
    "model.fit(interactions, epochs=30)\n",
    "\n",
    "# Generate predictions\n",
    "test_user_ids = [trainset.to_inner_uid(uid) for (uid, _, _) in testset]\n",
    "test_item_ids = [trainset.to_inner_iid(iid) for (_, iid, _) in filtered_testset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "180e7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate valid indices (original testset positions)\n",
    "valid_indices = []\n",
    "test_user_ids = []\n",
    "test_item_ids = []\n",
    "\n",
    "for idx, (uid, iid, rating) in enumerate(testset):\n",
    "    try:\n",
    "        u_inner = trainset.to_inner_uid(uid)\n",
    "        i_inner = trainset.to_inner_iid(iid)\n",
    "        valid_indices.append(idx)  # Store original testset index\n",
    "        test_user_ids.append(u_inner)\n",
    "        test_item_ids.append(i_inner)\n",
    "    except ValueError:\n",
    "        continue  # Skip cold-start users/items\n",
    "\n",
    "# Predict for valid pairs\n",
    "preds = model.predict(test_user_ids, test_item_ids).flatten()\n",
    "\n",
    "# Create Prediction objects using original testset indices\n",
    "predictions = [\n",
    "    Prediction(\n",
    "        uid=testset[idx][0], \n",
    "        iid=testset[idx][1], \n",
    "        r_ui=testset[idx][2], \n",
    "        est=float(preds[j]),\n",
    "        details=None,\n",
    "    )\n",
    "    for j, idx in enumerate(valid_indices)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52279469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (200006,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions shape:\", preds.shape)  # Should be (n_predictions,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "041978bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "model_result = {'Model': config['name']}\n",
    "\n",
    "# Compute metrics\n",
    "metrics = compute_metrics(predictions)\n",
    "model_result.update(metrics)\n",
    "model_result.update({'Best Params': str(best_params)})\n",
    "results.append(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d08b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training LightFM-WARP ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tocoo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m interactions \u001b[38;5;241m=\u001b[39m surprise_to_lightfm(trainset)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m LightFM(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[1;32m     14\u001b[0m test_user_ids \u001b[38;5;241m=\u001b[39m [trainset\u001b[38;5;241m.\u001b[39mto_inner_uid(uid) \u001b[38;5;28;01mfor\u001b[39;00m (uid, _, _) \u001b[38;5;129;01min\u001b[39;00m testset]\n",
      "File \u001b[0;32m/mnt/newdisk/miniconda3/envs/MachineLab10/lib/python3.10/site-packages/lightfm/lightfm.py:550\u001b[0m, in \u001b[0;36mLightFM.fit\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# Discard old results, if any\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_state()\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_partial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/newdisk/miniconda3/envs/MachineLab10/lib/python3.10/site-packages/lightfm/lightfm.py:617\u001b[0m, in \u001b[0;36mLightFM.fit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03mFit the model.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    the fitted model\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# We need this in the COO format.\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# If that's already true, this is a no-op.\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m interactions \u001b[38;5;241m=\u001b[39m \u001b[43minteractions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtocoo\u001b[49m()\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interactions\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m CYTHON_DTYPE:\n\u001b[1;32m    620\u001b[0m     interactions\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m interactions\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(CYTHON_DTYPE)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tocoo'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for config in models:\n",
    "    print(f\"\\n=== Training {config['name']} ===\")\n",
    "    model_result = {'Model': config['name']}\n",
    "    \n",
    "    if config['algo'] == LightFM:\n",
    "        # LightFM training\n",
    "        interactions = surprise_to_lightfm(trainset)\n",
    "        model = LightFM(**best_params)\n",
    "        model.fit(interactions, epochs=30)\n",
    "        \n",
    "        # Generate predictions\n",
    "        test_user_ids = [trainset.to_inner_uid(uid) for (uid, _, _) in testset]\n",
    "        test_item_ids = [trainset.to_inner_iid(iid) for (_, iid, _) in testset]\n",
    "        \n",
    "        # Generate valid indices (original testset positions)\n",
    "        valid_indices = []\n",
    "        test_user_ids = []\n",
    "        test_item_ids = []\n",
    "\n",
    "        for idx, (uid, iid, rating) in enumerate(testset):\n",
    "            try:\n",
    "                u_inner = trainset.to_inner_uid(uid)\n",
    "                i_inner = trainset.to_inner_iid(iid)\n",
    "                valid_indices.append(idx)  # Store original testset index\n",
    "                test_user_ids.append(u_inner)\n",
    "                test_item_ids.append(i_inner)\n",
    "            except ValueError:\n",
    "                continue  # Skip cold-start users/items\n",
    "\n",
    "        # Predict for valid pairs\n",
    "        preds = model.predict(test_user_ids, test_item_ids)\n",
    "\n",
    "        # Create Prediction objects using original testset indices\n",
    "        predictions = [\n",
    "            Prediction(\n",
    "                uid=testset[idx][0], \n",
    "                iid=testset[idx][1], \n",
    "                r_ui=testset[idx][2], \n",
    "                est=preds[j],\n",
    "                details=None,\n",
    "            )\n",
    "            for j, idx in enumerate(valid_indices)\n",
    "        ]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics(predictions)\n",
    "    model_result.update(metrics)\n",
    "    model_result.update({'Best Params': str(best_params[config['name']])})\n",
    "    results.append(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c6ea7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c4fef_row0_col0, #T_c4fef_row0_col1, #T_c4fef_row0_col2, #T_c4fef_row0_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c4fef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c4fef_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c4fef_level0_col1\" class=\"col_heading level0 col1\" >RMSE</th>\n",
       "      <th id=\"T_c4fef_level0_col2\" class=\"col_heading level0 col2\" >Acc (±0.5)</th>\n",
       "      <th id=\"T_c4fef_level0_col3\" class=\"col_heading level0 col3\" >Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c4fef_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c4fef_row0_col0\" class=\"data row0 col0\" >LightFM-WARP</td>\n",
       "      <td id=\"T_c4fef_row0_col1\" class=\"data row0 col1\" >3.767</td>\n",
       "      <td id=\"T_c4fef_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_c4fef_row0_col3\" class=\"data row0 col3\" >{'item_alpha': 0.02,\n",
       "'learning_rate': 0.005,\n",
       "'loss': 'bpr',\n",
       "'no_components': 20,\n",
       "'random_state': 42,\n",
       "'user_alpha': 0.02}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x72b2b3358340>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Final Results ===\")\n",
    "\n",
    "# Formatting\n",
    "styled_df = results_df.style.format({\n",
    "    'RMSE': '{:.3f}',\n",
    "    'Acc (±1)': '{:.1f}%',\n",
    "    'Best Params': lambda x: x.replace(', ', ',\\n')\n",
    "}).set_properties(**{'text-align': 'left'})\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeafef7",
   "metadata": {},
   "source": [
    "# TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6307ce88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x72b2b34feb30>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=20, loss='bpr', learning_rate=0.005, item_alpha=0.02, user_alpha=0.02, random_state=42)\n",
    "model.fit(interactions, epochs=30, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8c1a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_user_ids, test_item_ids, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25b33e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at k=5: 0.40\n"
     ]
    }
   ],
   "source": [
    "score = precision_at_k(model, interactions, k=5, num_threads=4)\n",
    "print(f\"Precision at k=5: {score.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e06ee873",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float32' object has no attribute 'est'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([pred\u001b[38;5;241m.\u001b[39mest \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions])\n\u001b[1;32m      2\u001b[0m actuals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([pred\u001b[38;5;241m.\u001b[39mr_ui \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions])\n",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mest\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions])\n\u001b[1;32m      2\u001b[0m actuals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([pred\u001b[38;5;241m.\u001b[39mr_ui \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float32' object has no attribute 'est'"
     ]
    }
   ],
   "source": [
    "preds = np.array([pred.est for pred in predictions])\n",
    "actuals = np.array([pred.r_ui for pred in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93534d36",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35861455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameter grids\n",
    "models = [\n",
    "    {\n",
    "        'name': 'LightFM-WARP',\n",
    "        'algo': LightFM,\n",
    "        'params': {\n",
    "            'no_components': [20, 50],\n",
    "            'loss': ['warp'],\n",
    "            'learning_rate': [0.01, 0.03],\n",
    "            'item_alpha': [0.02, 0.1],\n",
    "            'user_alpha': [0.02, 0.1],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'LightFM-BPR',\n",
    "        'algo': LightFM,\n",
    "        'params': {\n",
    "            'no_components': [20, 50],\n",
    "            'loss': ['bpr'],\n",
    "            'learning_rate': [0.01, 0.03],\n",
    "            'item_alpha': [0.02, 0.1],\n",
    "            'user_alpha': [0.02, 0.1],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'SVD',\n",
    "        'algo': SVD,\n",
    "        'params': {\n",
    "            'n_factors': [50, 100, 150],\n",
    "            'n_epochs': [20, 30],\n",
    "            'lr_all': [0.005, 0.01],\n",
    "            'reg_all': [0.02, 0.1]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'KNNBasic',\n",
    "        'algo': KNNBasic,\n",
    "        'params': {\n",
    "            'k': [20, 40],\n",
    "            'sim_options': {\n",
    "                'name': ['msd', 'pearson'],\n",
    "                'user_based': [False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'NMF',\n",
    "        'algo': NMF,\n",
    "        'params': {\n",
    "            'n_factors': [10, 15],\n",
    "            'n_epochs': [50, 100]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'CoClustering',\n",
    "        'algo': CoClustering,\n",
    "        'params': {\n",
    "            'n_cltr_u': [3, 5],\n",
    "            'n_cltr_i': [3, 5],\n",
    "            'n_epochs': [20, 30]\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c144c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprise_to_lightfm(trainset):\n",
    "    \"\"\"Convert Surprise Trainset to COO matrix for LightFM\"\"\"\n",
    "    rows, cols, data = [], [], []\n",
    "    for uid in trainset.all_users():\n",
    "        user_ratings = trainset.ur[uid]\n",
    "        for iid, rating in user_ratings:\n",
    "            rows.append(uid)\n",
    "            cols.append(iid)\n",
    "            data.append(1)  # Use 1 for implicit feedback\n",
    "    return coo_matrix((data, (rows, cols))), trainset.n_users, trainset.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83abda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions, _, _ = surprise_to_lightfm(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your training loop:\n",
    "for model_config in models:\n",
    "    if 'LightFM' in model_config['name']:\n",
    "        # LightFM handling\n",
    "        #interactions, _, _ = surprise_to_lightfm(trainset)\n",
    "        \n",
    "        # Hyperparameter tuning\n",
    "        best_score = -np.inf\n",
    "        best_params = {}\n",
    "        for params in ParameterGrid(model_config['params']):\n",
    "            print(f\"Training {model_config['name']} with params: {params}\")\n",
    "            model = LightFM(**params)\n",
    "            model.fit(interactions, epochs=10, verbose=False)\n",
    "            score = precision_at_k(model, interactions, k=5).mean()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "                \n",
    "        # Final training\n",
    "        print(f\"[Final] Training {model_config['name']} with params: {params}\")\n",
    "        final_model = LightFM(**best_params)\n",
    "        final_model.fit(interactions, epochs=20)\n",
    "        \n",
    "        # Generate predictions (example for LightFM)\n",
    "        user_ids = np.arange(interactions.shape[0])\n",
    "\n",
    "    else:\n",
    "    # Original Surprise handling\n",
    "        print(f\"Training {model_config['name']} with params: {params}\")\n",
    "        gs = GridSearchCV(\n",
    "            model_config['algo'],\n",
    "            model_config['params'],\n",
    "            measures=['rmse'],\n",
    "            cv=5\n",
    "        )\n",
    "        gs.fit(data)\n",
    "        best_model = gs.best_estimator['rmse']\n",
    "        best_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845292d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert testset to LightFM-compatible format\n",
    "test_user_ids = [trainset.to_inner_uid(uid) for (uid, _, _) in testset]\n",
    "test_item_ids = [trainset.to_inner_iid(iid) for (_, iid, _) in testset]\n",
    "\n",
    "# Generate predictions only for test pairs\n",
    "test_preds = final_model.predict(test_user_ids, test_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = final_model.predict(user_ids, np.arange(interactions.shape[1]))\n",
    "#print(\"Train precision: %.2f\" % precision_at_k(model, interactions, k=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b4f57",
   "metadata": {},
   "source": [
    "best_params = {}\n",
    "\n",
    "for model_config in models:\n",
    "    print(f\"\\n=== Tuning {model_config['name']} ===\")\n",
    "    gs = GridSearchCV(\n",
    "        model_config['algo'],\n",
    "        model_config['params'],\n",
    "        measures=['rmse'],\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        pre_dispatch='2*n_jobs'\n",
    "    )\n",
    "    gs.fit(data)\n",
    "    best_params[model_config['name']] = gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f81d7b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_config in models:\n",
    "    if 'LightFM' in model_config['name']:\n",
    "        continue  # Skip LightFM for now\n",
    "    print(f\"\\n=== Training {model_config['name']} ===\")\n",
    "    \n",
    "    # Initialize with best params\n",
    "    model = model_config['algo'](**best_params[model_config['name']])\n",
    "    model.fit(trainset)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.test(testset)\n",
    "    preds = np.array([pred.est for pred in predictions])\n",
    "    actuals = np.array([pred.r_ui for pred in predictions])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(np.mean((preds - actuals) ** 2))\n",
    "    tol_1 = np.mean(np.abs(preds - actuals) <= 1) * 100\n",
    "    tol_05 = np.mean(np.abs(preds - actuals) <= 0.5) * 100\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_config['name'],\n",
    "        'Best Params': best_params[model_config['name']],\n",
    "        'RMSE': rmse,\n",
    "        'Acc (±1)': tol_1,\n",
    "        'Acc (±0.5)': tol_05\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80316310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model's predictions:\n",
    "tolerance = 1\n",
    "stricter_tolerance = 0.5\n",
    "\n",
    "for model_result in results:\n",
    "    model_name = model_result['Model']\n",
    "    print(f\"\\n{model_name} Accuracy:\")\n",
    "    print(f\"Within ±{tolerance} Stars: {model_result['Acc (±1)']:.2f}%\")\n",
    "    print(f\"Within ±{stricter_tolerance} Stars: {model_result['Acc (±0.5)']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06806afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = np.array([pred.est for pred in test_preds]).reshape(-1, 1)\n",
    "#actuals = np.array([pred.r_ui for pred in test_preds]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba540de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predictions\n",
    "#for pred in test_preds:\n",
    "#    print(f\"Predicted={pred.est:.2f}, Actual={pred.r_ui}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f51e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results in DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Optional: Formatting for better display\n",
    "results_df.style.format({\n",
    "    'RMSE': '{:.4f}',\n",
    "    'Acc (±1)': '{:.2f}%',\n",
    "    'Acc (±0.5)': '{:.2f}%'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tolerance (e.g., predictions within ±1 stars are \"correct\")\n",
    "tolerance = 1\n",
    "correct = np.abs(preds - actuals) <= tolerance\n",
    "test_accuracy = np.mean(correct) * 100\n",
    "\n",
    "# Define stricter tolerance (e.g., predictions within ±0.5 stars are \"correct\")\n",
    "stricter_tolerance = 0.5\n",
    "s_correct = np.abs(preds - actuals) <= stricter_tolerance\n",
    "s_test_accuracy = np.mean(s_correct) * 100\n",
    "\n",
    "print(f\"Accuracy (Within ±{tolerance} Stars): {test_accuracy:.2f}%\")\n",
    "print(f\"Accuracy (Within ±{stricter_tolerance} Stars): {s_test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "dump(model, '../models/cf_model.pkl')  # Or use .joblib extension\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa8235",
   "metadata": {},
   "source": [
    "# Model Training with 10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Upgrade\n",
    "beeg_data = pd.read_csv(r\"K:\\MachineProject\\Data\\ml-32m\\ratings.dat\", sep='::', engine='python', names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "\n",
    "# Drop the Timestamp column\n",
    "beeg_data = beeg_data.drop('Timestamp', axis=1)\n",
    "beeg_data.columns = ['UserID', 'MovieID', 'Rating']\n",
    "beeg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd291d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user = beeg_data.groupby('UserID')['Rating'].count().reset_index()\n",
    "ratings_per_user.columns = ['user_id', 'num_ratings']\n",
    "print(ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4844132",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ratings_per_user['num_ratings'].describe(percentiles=[0.1, 0.5, 0.9])\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeg_data[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeg_data[\"MovieID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d651be",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeg_data[\"UserID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeg_data['UserID'] = beeg_data['UserID'].astype('int32')\n",
    "beeg_data['MovieID'] = beeg_data['MovieID'].astype('int32')\n",
    "beeg_data['Rating'] = beeg_data['Rating'].astype('float16')\n",
    "\n",
    "beeg_data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by user_id (ensure all users are represented)\n",
    "subsampled_df, _ = sklearn_split(\n",
    "    beeg_data,\n",
    "    test_size=0.5,\n",
    "    stratify=beeg_data['UserID'],  # Preserve user distribution\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab49a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(beeg_data['Rating'].min(), beeg_data['Rating'].max()))\n",
    "data = Dataset.load_from_df(beeg_data[['UserID', 'MovieID', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(location='./cache', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [50, 100],  # Test latent dimensions\n",
    "    'n_epochs': [20, 30],\n",
    "    'lr_all': [0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    SVD,\n",
    "    param_grid,\n",
    "    measures=['rmse'],\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    ")\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score and params\n",
    "print(f\"Best RMSE: {gs.best_score['rmse']}\")\n",
    "print(f\"Best params: {gs.best_params['rmse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876697af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09545c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b27573",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.test(testset)\n",
    "accuracy.rmse(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([pred.est for pred in test_preds]).reshape(-1, 1)\n",
    "actuals = np.array([pred.r_ui for pred in test_preds]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d256c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tolerance (e.g., predictions within ±1 stars are \"correct\")\n",
    "tolerance = 1\n",
    "correct = np.abs(preds - actuals) <= tolerance\n",
    "test_accuracy = np.mean(correct) * 100\n",
    "\n",
    "# Define stricter tolerance (e.g., predictions within ±0.5 stars are \"correct\")\n",
    "stricter_tolerance = 0.5\n",
    "s_correct = np.abs(preds - actuals) <= stricter_tolerance\n",
    "s_test_accuracy = np.mean(s_correct) * 100\n",
    "\n",
    "print(f\"Accuracy (Within ±{tolerance} Stars): {test_accuracy:.2f}%\")\n",
    "print(f\"Accuracy (Within ±{stricter_tolerance} Stars): {s_test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ad150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "dump(model, '../models/cf_model_2.pkl')  # Or use .joblib extension\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4e897",
   "metadata": {},
   "source": [
    "# Model Training with 32M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645626c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Upgrade\n",
    "beegar_data = pd.read_csv(r\"K:\\MachineProject\\Data\\ml-32m\\ratings.csv\")\n",
    "\n",
    "# Drop the Timestamp column\n",
    "beegar_data = beegar_data.drop('timestamp', axis=1)\n",
    "beegar_data.columns = ['UserID', 'MovieID', 'Rating']\n",
    "beegar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user = beegar_data.groupby('UserID')['Rating'].count().reset_index()\n",
    "ratings_per_user.columns = ['user_id', 'num_ratings']\n",
    "print(ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118825b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ratings_per_user['num_ratings'].describe(percentiles=[0.1, 0.5, 0.9])\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee1c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beegar_data[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "beegar_data[\"MovieID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82463015",
   "metadata": {},
   "outputs": [],
   "source": [
    "beegar_data[\"UserID\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beegar_data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beegar_data['UserID'] = beegar_data['UserID'].astype('int32')\n",
    "beegar_data['MovieID'] = beegar_data['MovieID'].astype('int32')\n",
    "beegar_data['Rating'] = beegar_data['Rating'].astype('float16')\n",
    "\n",
    "beegar_data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ee50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by user_id (ensure all users are represented)\n",
    "subsampled_df, _ = sklearn_split(\n",
    "    beegar_data,\n",
    "    test_size=0.5,\n",
    "    stratify=beegar_data['UserID'],  # Preserve user distribution\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f50baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(beegar_data['Rating'].min(), beegar_data['Rating'].max()))\n",
    "data = Dataset.load_from_df(beegar_data[['UserID', 'MovieID', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93440a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(location='./cache', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8851ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [50, 100],  # Test latent dimensions\n",
    "    'n_epochs': [20, 30],\n",
    "    'lr_all': [0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    SVD,\n",
    "    param_grid,\n",
    "    measures=['rmse'],\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    ")\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score and params\n",
    "print(f\"Best RMSE: {gs.best_score['rmse']}\")\n",
    "print(f\"Best params: {gs.best_params['rmse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5fffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71fabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.test(testset)\n",
    "accuracy.rmse(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([pred.est for pred in test_preds]).reshape(-1, 1)\n",
    "actuals = np.array([pred.r_ui for pred in test_preds]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tolerance (e.g., predictions within ±1 stars are \"correct\")\n",
    "tolerance = 1\n",
    "correct = np.abs(preds - actuals) <= tolerance\n",
    "test_accuracy = np.mean(correct) * 100\n",
    "\n",
    "# Define stricter tolerance (e.g., predictions within ±0.5 stars are \"correct\")\n",
    "stricter_tolerance = 0.5\n",
    "s_correct = np.abs(preds - actuals) <= stricter_tolerance\n",
    "s_test_accuracy = np.mean(s_correct) * 100\n",
    "\n",
    "print(f\"Accuracy (Within ±{tolerance} Stars): {test_accuracy:.2f}%\")\n",
    "print(f\"Accuracy (Within ±{stricter_tolerance} Stars): {s_test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "dump(model, '../models/cf_model_2.pkl')  # Or use .joblib extension\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLab10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
